{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EXhlQWSsUJQr",
        "outputId": "a490d35d-1565-46a7-9851-c222429d6497"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.4/47.4 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m441.4/441.4 kB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m88.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m305.5/305.5 kB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m470.2/470.2 kB\u001b[0m \u001b[31m36.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.9/147.9 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.5/19.5 MB\u001b[0m \u001b[31m97.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.2/98.2 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m60.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.6/62.6 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.4/239.4 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m804.0/804.0 kB\u001b[0m \u001b[31m49.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m95.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m92.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m48.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m84.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m82.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.8/65.8 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.7/55.7 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.5/118.5 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.2/196.2 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.2/71.2 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m76.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m453.1/453.1 kB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "google-colab 1.0.0 requires requests==2.32.3, but you have requests 2.31.0 which is incompatible.\n",
            "google-generativeai 0.8.5 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.6.18 which is incompatible.\n",
            "dataproc-spark-connect 0.8.1 requires tqdm>=4.67, but you have tqdm 4.65.2 which is incompatible.\n",
            "pymc 5.23.0 requires rich>=13.7.1, but you have rich 13.4.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -q --upgrade langchain langchain_google_genai langchain-core langchain_community docs2txt langchain_chroma pypdf sentence_transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyADu_1yOYB7lwnoDaYW7cGGBQviZJO1MNI\"\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = \"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\"\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = \"rag-chatbot\""
      ],
      "metadata": {
        "id": "rVyeuj6FUyKo"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ast import Str\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\")\n",
        "response = llm.invoke(\"Tell me a simple joke about coding and AI.\")\n",
        "\n",
        "output_parser = StrOutputParser()\n",
        "output_parser.invoke(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "8mFbXqALXsfq",
        "outputId": "53c87d8d-5787-45da-b3a6-a5161b64f4ca"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Why did the AI get a syntax error?\\n\\nBecause it learned to code from a human!'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain = llm | output_parser\n",
        "chain.invoke(\"Tell me a story of one line\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "qISp5JLgYCQ9",
        "outputId": "57a6516d-db7b-46bc-d09f-d8fcb0bbab6f"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'She planted the seed, watched it grow into a towering tree, and then carved her own coffin from its wood.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "class Review(BaseModel):\n",
        "  topic:str = Field(description=\"Name of the topic\")\n",
        "  summary:str = Field(description=\"Brief summary of the topic\")\n",
        "  rating: float = Field(description=\"Overall rating of the topic english\")\n",
        "  pros: List[str] = Field(description=\"List the positive aspects of the topic\")\n",
        "  cons: List[str] = Field(description=\"List the negative aspects of the topic\")\n",
        "\n",
        "prompt_text = '''\n",
        "  One of the standard tasks in natural language generation is text summarization. Text summarization can include many different flavors and domains. In fact, one of the most promising applications of language models is the ability to summarize articles and concepts into quick and easy-to-read summaries.\n",
        "  Let's try a basic summarization task using prompts.\n",
        "'''\n",
        "\n",
        "structured_llm = llm.with_structured_output(Review)\n",
        "output = structured_llm.invoke(prompt_text)\n",
        "print(output)\n",
        "print(output.pros)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B5n9MwQLYziB",
        "outputId": "f3b933a4-5f18-47e6-e788-989678f4cf40"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "topic='Text Summarization' summary='Text summarization is a key NLP task, enabling quick understanding of documents, and is a promising application for language models.' rating=4.5 pros=['useful for quick understanding'] cons=['difficult to summarize long articles']\n",
            "['useful for quick understanding']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "prompt = ChatPromptTemplate.from_template(\"Tell me a joke about {topic}\")\n",
        "prompt.invoke({\"topic\": \"sports\"})\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8zsO7XMCaI-e",
        "outputId": "385a911c-32b6-4d3e-cd5b-1871e366075f"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatPromptValue(messages=[HumanMessage(content='Tell me a joke about sports', additional_kwargs={}, response_metadata={})])"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain = prompt | llm | output_parser\n",
        "result = chain.invoke({\"topic\": \"dark humour coding\"})\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CAm0-_avbPfE",
        "outputId": "cefe8bfc-43f5-4be6-f7be-67bac89bffe9"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Why did the senior developer look so calm during the massive production outage?\n",
            "\n",
            "Because he said, \"Finally, a chance to really *debug* this system. I've always wanted to see what makes it *scream*.\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "\n",
        "messages = [\n",
        "    SystemMessage(content=\"You are a helpful AI Assistant\"),\n",
        "    HumanMessage(content=\"Tell me a joke about the PM of India in one line\")\n",
        "]\n",
        "\n",
        "response = llm.invoke(messages)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m9cURd8zbbak",
        "outputId": "f1dd6d63-f766-4e1a-fec5-b634802805ae"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "content='Why did the PM bring a ladder to his rally? Because he heard his approval ratings were soaring!' additional_kwargs={} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': []} id='run--9697fc7c-5e63-4ab6-a211-26669c12bf54-0' usage_metadata={'input_tokens': 19, 'output_tokens': 20, 'total_tokens': 1228, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 1189}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "template = ChatPromptTemplate([\n",
        "    (\"system\", \"Helpful Assistant\"),\n",
        "    (\"human\", \"Tell me about {topic}\")\n",
        "])\n",
        "\n",
        "chain = template | llm\n",
        "response = chain.invoke({\"topic\": \"coding\"})\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abY08Y03cafc",
        "outputId": "4db58510-e397-4ce7-b71f-b42497ffa1cd"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "content='Coding, at its heart, is the process of **giving instructions to a computer** in a language it understands. Think of it like writing a recipe, but instead of telling a person how to bake a cake, you\\'re telling a machine how to perform a specific task or solve a problem.\\n\\nHere\\'s a breakdown of what coding is all about:\\n\\n---\\n\\n### What is Coding?\\n\\n1.  **Instructions for Machines:** Computers are incredibly powerful but incredibly dumb. They can only do exactly what they\\'re told. Coding is the act of writing these precise, step-by-step instructions.\\n2.  **Programming Languages:** Since computers don\\'t understand human languages directly, we use \"programming languages\" to communicate with them. These languages (like Python, Java, JavaScript, C++, Ruby, etc.) have specific syntax (grammar) and rules that allow us to translate our ideas into machine-readable code.\\n3.  **Problem Solving:** At its core, coding is about solving problems. Whether it\\'s automating a repetitive task, building a website, or creating a complex AI, you\\'re breaking down a big problem into smaller, manageable steps that a computer can execute.\\n\\n---\\n\\n### What Can You Do With Coding? (Applications)\\n\\nThe applications of coding are virtually limitless and touch almost every aspect of modern life:\\n\\n*   **Websites & Web Applications:**\\n    *   **Front-end Development:** What you see and interact with (buttons, text, images). Uses languages like HTML, CSS, JavaScript.\\n    *   **Back-end Development:** The server, database, and logic that powers the website behind the scenes (user authentication, data storage). Uses languages like Python, Node.js (JavaScript), Ruby, PHP, Java, C#.\\n*   **Mobile Apps:** Applications for smartphones and tablets (iOS and Android). Uses languages like Swift (for iOS), Kotlin or Java (for Android), or frameworks like React Native/Flutter (JavaScript/Dart) for cross-platform apps.\\n*   **Desktop Software:** Programs that run on your computer (e.g., Microsoft Word, Photoshop, video games). Uses languages like C++, Java, Python, C#.\\n*   **Games:** From simple mobile games to complex AAA titles. Uses languages like C++, C#, Python, and game engines like Unity or Unreal Engine.\\n*   **Data Science & Machine Learning/AI:** Analyzing large datasets, building predictive models, creating artificial intelligence. Uses languages like Python (with libraries like TensorFlow, PyTorch, Pandas) and R.\\n*   **Automation:** Automating repetitive tasks, controlling robots, managing smart home devices. Python is very popular for this.\\n*   **Cybersecurity:** Developing tools to protect systems, analyzing vulnerabilities, creating secure software.\\n*   **Embedded Systems:** Code for devices like smart TVs, car systems, medical equipment, and IoT (Internet of Things) devices. Often uses C, C++.\\n\\n---\\n\\n### How Does Coding Work? (Basic Concepts)\\n\\n1.  **Syntax:** The specific rules and structure of a programming language. Just like English has grammar rules, so do programming languages. A misplaced comma or misspelled word can break your code.\\n2.  **Logic & Algorithms:** This is the \"thinking\" part. An **algorithm** is a step-by-step procedure for solving a problem. Coders design these logical steps before writing the actual code.\\n3.  **Variables:** Named containers for storing data (e.g., a variable named `score` might hold the number 100).\\n4.  **Data Types:** The kind of data a variable holds (e.g., text, numbers, true/false values).\\n5.  **Control Flow:** Instructions that tell the computer *when* to execute certain pieces of code (e.g., `if` a condition is true, `then` do this; `loop` through these instructions multiple times).\\n6.  **Functions/Methods:** Reusable blocks of code that perform a specific task.\\n7.  **Debugging:** The process of finding and fixing errors (bugs) in your code. It\\'s an essential skill for any coder!\\n8.  **Compilers/Interpreters:** Tools that translate your human-readable code into machine code (binary 0s and 1s) that the computer\\'s processor can understand and execute.\\n\\n---\\n\\n### Who Codes?\\n\\nPeople who code are often called **programmers**, **developers**, or **software engineers**. They come from all walks of life and backgrounds, but they typically share qualities like:\\n*   Logical thinking\\n*   Problem-solving aptitude\\n*   Attention to detail\\n*   Patience\\n*   Creativity\\n\\n---\\n\\n### Why Learn Coding?\\n\\n*   **High Demand & Good Pay:** The tech industry is booming, and skilled coders are highly sought after.\\n*   **Problem-Solving Skills:** Coding trains your brain to think logically and break down complex problems.\\n*   **Creativity & Building:** You can bring your ideas to life and build things that impact the world.\\n*   **Understanding Technology:** It demystifies the digital world around you.\\n*   **Automation:** Automate tedious tasks in your personal and professional life.\\n*   **Flexibility:** Many coding jobs offer remote work opportunities.\\n\\n---\\n\\nIn essence, coding is the language of the digital age, enabling us to instruct computers to perform incredible feats, from sending a text message to exploring Mars. It\\'s a challenging but incredibly rewarding field.' additional_kwargs={} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': []} id='run--27652200-b5b3-4840-92a5-66e666e359f8-0' usage_metadata={'input_tokens': 8, 'output_tokens': 1161, 'total_tokens': 2255, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 1086}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader, Docx2txtLoader\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from typing import List\n",
        "from langchain_core.documents import Document\n",
        "import os\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200, length_function=len)\n",
        "\n",
        "docx_loader = Docx2txtLoader(\"/content/docs/Aryan_Chauhan_Resume.docx\")\n",
        "docs = docx_loader.load()\n",
        "\n",
        "splits = text_splitter.split_documents(docs)\n",
        "print(f\"Doc split with length: {len(splits)} chunks\")\n",
        "print(len(docs))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JzCcBcNjc3sA",
        "outputId": "1d79c4fe-1008-4efd-95d7-dbd02db9e78c"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Doc split with length: 6 chunks\n",
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "docs[0] # gives the first doc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GEo6s253hjRK",
        "outputId": "18fa2c6e-516f-491e-b148-09b4ee56e381"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(metadata={'source': '/content/docs/Aryan_Chauhan_Resume.docx'}, page_content='ARYAN CHAUHAN\\n\\nPune 411020, India | work@aryancodes.dev | +91 9049122622 | https://www.aryancodes.dev/| https://github.com/aryanc381\\n\\n\\n\\nPROFILE\\n\\nInnovative, responsible and impact-driven Full Stack AI Engineer on a mission to build intelligent systems that are ethical, scalable, and transformative for Indian businesses and societies. A strong foundation in AI-ML, Agentic-AI, Web Development, NLP and Computer Vision backed by experience in building AI-driven projects that prioritize performance, usability, and reliability.\\n\\n\\tEDUCATION\\n\\n\\tMIT World Peace University, Pune, India\\t   June 2026\\n\\nOngoing - B-Tech Electronics & Electrical Engineering (Specialization: AI-ML) \\n\\n\\tArham Jr College, Pune, India\\t    June 2022\\n\\nSecured 77.77% in Class 12th Higher Secondary Certificate Examination (HSC Board)\\n\\n\\tSymbiosis Primary & Secondary School, Pune, India\\t   Aug 2020\\n\\nSecured 83.20% in Class 10th examination (SSC Board)\\n\\n\\n\\nEXPERIENCE\\n\\n\\tInnovators Hub, Pune \\t    Pune, India\\n\\n\\tCore Software Team Member (7+ months)\\t     Aug 2024 – Present 2025\\n\\n\\t\\tContributor to design & development of Neural Network powered applications. Lead a team of 5 which successfully developed a Computer Vision AI-powered interview system enabling real-time, bidirectional communication for individuals with speech and hearing impairments for Centre for Education and R&D for Deaf and Dumb, Pune.\\n\\n\\tRancho Labs, IIT-Delhi (2 months)\\t    Remote Setup\\n\\n\\tAdvanced AI & Python Instructor\\t     May 2025 – Sept 2025\\n\\n\\tMentoring young aspiring developers by teaching them DSA, NLP, GenAI, Python and Advance AI algorithms from the ground up, enabling them to build & deploy real-world applications.\\n\\n\\tTexephyr, MIT Pune (17 months)\\t        Pune, India\\n\\n\\tTechnical Manager\\t         Mar 2022 – Jul 2023\\n\\n\\tManaged the technical strategy and execution of Texephyr’s core GenAI & NLP projects along with conducting hackathons, coding challenges, and tech workshops. Delivered 2 flagship projects 12 days ahead of schedule, trained 50+ students about LLM Architectures from the ground up.\\n\\nPROJECTS\\n\\n\\n\\n\\tKoel (2 months)  -  NLP                                                                                                                                   May 2025 – Jun 2025\\n\\n\\tDeveloped an intelligent, multilingual voice-to-voice AI system enabling real-time natural conversations in Indian languages. Built with React Native and FastAPI, Koel integrates Sarvam-M LLM with RAG for PDF-based contextual responses, delivers real-time web results, and ensures low-latency voice processing through a scalable architecture.\\n\\n\\tRajVaani v0.0.8 (2 months) - NLP                                                                                                                April 2025 – June 2025\\n\\n\\t\\tA milestone in building the world’s first voice AI app for Rajasthan - a mission-driven, end-to-end ASR-TTS system built with React and integrated with an LLM - empowering 8 crore people to access information and next-gen AI tech in their native Marwadi dialect, bridging the digital language divide through AI.\\n\\n\\tSignLangApp (3 months) – Computer Vision\\t        Oct 2024 - Dec 2024\\n\\n\\t\\tA real-time computer vision interview system for the speech and hearing impaired using GRU for hand sign recognition, DeepSeek LLM for the final response generation and Flask making a heavy backend, and a lightweight Streamlit frontend.\\n\\n\\tDeepDefend (4 months) – Computer Vision\\t        Sept 2023 – Dec 2023\\n\\n\\tAn AI-powered system for detecting face-swap deepfake videos using advanced facial forensics and Computer Vision models like CNNs, Resnet50, VGG16 and real-time image processing techniques to ensure content authenticity and combat misinformation.\\n\\nSKILLS & LANGUAGE PROFICIENCY\\n\\n\\t\\tLanguages: C, C++, Java, Python, HTML, CSS, JavaScript.\\n\\n\\t\\tNeural Networks: ANN, CNN, RNN, LSTM & BiLSTM, GRU & BiGRU, Transformers, Attention Mechanism.\\n\\n\\t\\tNLP: Whisper, Wav2Vec, Conformer, Tacotron, FastSpeech, VITS, VoiceCloning, Neural Vocoders, MFCCs, STT.\\n\\n\\tComputer Vision: Yolo, Vision Transformers, Real-time Video & Image Processing, GAN, Opencv, Mediapipe, Dlib.\\n\\n\\tAI and AgenticAI Infrastructure: PyTorch, Tensorflow, Keras, HuggingFace, Langchain, LoRa, QLoRa, RAG, MCP.\\n\\n\\tWebDev Infrastructure: MERN, React, UI/UX, AWS, RunPod, FastAPI, Flask, Firebase, Streamlit.\\n\\n\\tSoft Skills: Strong Communication, Leadership, Critical Thinking, Fast Adaptability, Team Collaboration, Responsible & Hardworking.\\n\\nACCOMPLISHMENTS\\n\\n\\n\\n\\tHACKXMIT 2025: Achieved a remarkable 1st position and won the competition – Koel.\\n\\n\\t\\tPCCOE Hack24: Secured 3rd position – SignLangApp.\\n\\n\\tSIH Zonal Round 2023: Secured 4th position in Top 15 – DeepDefend.\\n\\n\\tTexephyr 2022: Secured 3rd position & management role - created a CNN from scratch (w/o tensorflow) for Vehicle Detection.\\n\\nEXTRA CURRICULAR ACTIVITIES\\n\\n\\n\\n\\tEEE Department Basketball Team Captain – 7 major victories.\\n\\n\\tTrinity College of Music London - Piano Grade 5 Distinction.')"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "splits[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DCeFuqnikiTp",
        "outputId": "c435123f-be4e-4b10-9174-751067f2733c"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(metadata={'source': '/content/docs/Aryan_Chauhan_Resume.docx'}, page_content='ARYAN CHAUHAN\\n\\nPune 411020, India | work@aryancodes.dev | +91 9049122622 | https://www.aryancodes.dev/| https://github.com/aryanc381\\n\\n\\n\\nPROFILE\\n\\nInnovative, responsible and impact-driven Full Stack AI Engineer on a mission to build intelligent systems that are ethical, scalable, and transformative for Indian businesses and societies. A strong foundation in AI-ML, Agentic-AI, Web Development, NLP and Computer Vision backed by experience in building AI-driven projects that prioritize performance, usability, and reliability.\\n\\n\\tEDUCATION\\n\\n\\tMIT World Peace University, Pune, India\\t   June 2026\\n\\nOngoing - B-Tech Electronics & Electrical Engineering (Specialization: AI-ML) \\n\\n\\tArham Jr College, Pune, India\\t    June 2022\\n\\nSecured 77.77% in Class 12th Higher Secondary Certificate Examination (HSC Board)\\n\\n\\tSymbiosis Primary & Secondary School, Pune, India\\t   Aug 2020\\n\\nSecured 83.20% in Class 10th examination (SSC Board)\\n\\n\\n\\nEXPERIENCE\\n\\n\\tInnovators Hub, Pune \\t    Pune, India')"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_documents(folder_path : str) -> List[Document]:\n",
        "  documents = []\n",
        "  for filename in os.listdir(folder_path):\n",
        "    file_path = os.path.join(folder_path, filename)\n",
        "    if filename.endswith('.pdf'):\n",
        "      loader = PyPDFLoader(file_path)\n",
        "    elif filename.endswith('.docx'):\n",
        "      loader = Docx2txtLoader(file_path)\n",
        "    else:\n",
        "      print(f\"Unsupported filetype: {filename}\")\n",
        "      continue\n",
        "    documents.extend(loader.load())\n",
        "\n",
        "  return documents\n",
        "\n",
        "folder_path = \"/content/docs/\"\n",
        "documents = load_documents(folder_path)\n",
        "print(f\"No of documents loaded:{len(documents)}.\")\n",
        "\n",
        "splits = text_splitter.split_documents(documents)\n",
        "print(f\"Splitted docs in {len(splits)} chunks.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iof2shi7krNc",
        "outputId": "7a02edc8-d915-4cfe-96f7-98f9ad884294"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No of documents loaded:2.\n",
            "Splitted docs in 12 chunks.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "documents[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-4PmBESEl3uu",
        "outputId": "8ff0a6a7-de7b-49aa-b449-a00a508df2de"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(metadata={'source': '/content/docs/Aryan_Chauhan_Resume.docx'}, page_content='ARYAN CHAUHAN\\n\\nPune 411020, India | work@aryancodes.dev | +91 9049122622 | https://www.aryancodes.dev/| https://github.com/aryanc381\\n\\n\\n\\nPROFILE\\n\\nInnovative, responsible and impact-driven Full Stack AI Engineer on a mission to build intelligent systems that are ethical, scalable, and transformative for Indian businesses and societies. A strong foundation in AI-ML, Agentic-AI, Web Development, NLP and Computer Vision backed by experience in building AI-driven projects that prioritize performance, usability, and reliability.\\n\\n\\tEDUCATION\\n\\n\\tMIT World Peace University, Pune, India\\t   June 2026\\n\\nOngoing - B-Tech Electronics & Electrical Engineering (Specialization: AI-ML) \\n\\n\\tArham Jr College, Pune, India\\t    June 2022\\n\\nSecured 77.77% in Class 12th Higher Secondary Certificate Examination (HSC Board)\\n\\n\\tSymbiosis Primary & Secondary School, Pune, India\\t   Aug 2020\\n\\nSecured 83.20% in Class 10th examination (SSC Board)\\n\\n\\n\\nEXPERIENCE\\n\\n\\tInnovators Hub, Pune \\t    Pune, India\\n\\n\\tCore Software Team Member (7+ months)\\t     Aug 2024 – Present 2025\\n\\n\\t\\tContributor to design & development of Neural Network powered applications. Lead a team of 5 which successfully developed a Computer Vision AI-powered interview system enabling real-time, bidirectional communication for individuals with speech and hearing impairments for Centre for Education and R&D for Deaf and Dumb, Pune.\\n\\n\\tRancho Labs, IIT-Delhi (2 months)\\t    Remote Setup\\n\\n\\tAdvanced AI & Python Instructor\\t     May 2025 – Sept 2025\\n\\n\\tMentoring young aspiring developers by teaching them DSA, NLP, GenAI, Python and Advance AI algorithms from the ground up, enabling them to build & deploy real-world applications.\\n\\n\\tTexephyr, MIT Pune (17 months)\\t        Pune, India\\n\\n\\tTechnical Manager\\t         Mar 2022 – Jul 2023\\n\\n\\tManaged the technical strategy and execution of Texephyr’s core GenAI & NLP projects along with conducting hackathons, coding challenges, and tech workshops. Delivered 2 flagship projects 12 days ahead of schedule, trained 50+ students about LLM Architectures from the ground up.\\n\\nPROJECTS\\n\\n\\n\\n\\tKoel (2 months)  -  NLP                                                                                                                                   May 2025 – Jun 2025\\n\\n\\tDeveloped an intelligent, multilingual voice-to-voice AI system enabling real-time natural conversations in Indian languages. Built with React Native and FastAPI, Koel integrates Sarvam-M LLM with RAG for PDF-based contextual responses, delivers real-time web results, and ensures low-latency voice processing through a scalable architecture.\\n\\n\\tRajVaani v0.0.8 (2 months) - NLP                                                                                                                April 2025 – June 2025\\n\\n\\t\\tA milestone in building the world’s first voice AI app for Rajasthan - a mission-driven, end-to-end ASR-TTS system built with React and integrated with an LLM - empowering 8 crore people to access information and next-gen AI tech in their native Marwadi dialect, bridging the digital language divide through AI.\\n\\n\\tSignLangApp (3 months) – Computer Vision\\t        Oct 2024 - Dec 2024\\n\\n\\t\\tA real-time computer vision interview system for the speech and hearing impaired using GRU for hand sign recognition, DeepSeek LLM for the final response generation and Flask making a heavy backend, and a lightweight Streamlit frontend.\\n\\n\\tDeepDefend (4 months) – Computer Vision\\t        Sept 2023 – Dec 2023\\n\\n\\tAn AI-powered system for detecting face-swap deepfake videos using advanced facial forensics and Computer Vision models like CNNs, Resnet50, VGG16 and real-time image processing techniques to ensure content authenticity and combat misinformation.\\n\\nSKILLS & LANGUAGE PROFICIENCY\\n\\n\\t\\tLanguages: C, C++, Java, Python, HTML, CSS, JavaScript.\\n\\n\\t\\tNeural Networks: ANN, CNN, RNN, LSTM & BiLSTM, GRU & BiGRU, Transformers, Attention Mechanism.\\n\\n\\t\\tNLP: Whisper, Wav2Vec, Conformer, Tacotron, FastSpeech, VITS, VoiceCloning, Neural Vocoders, MFCCs, STT.\\n\\n\\tComputer Vision: Yolo, Vision Transformers, Real-time Video & Image Processing, GAN, Opencv, Mediapipe, Dlib.\\n\\n\\tAI and AgenticAI Infrastructure: PyTorch, Tensorflow, Keras, HuggingFace, Langchain, LoRa, QLoRa, RAG, MCP.\\n\\n\\tWebDev Infrastructure: MERN, React, UI/UX, AWS, RunPod, FastAPI, Flask, Firebase, Streamlit.\\n\\n\\tSoft Skills: Strong Communication, Leadership, Critical Thinking, Fast Adaptability, Team Collaboration, Responsible & Hardworking.\\n\\nACCOMPLISHMENTS\\n\\n\\n\\n\\tHACKXMIT 2025: Achieved a remarkable 1st position and won the competition – Koel.\\n\\n\\t\\tPCCOE Hack24: Secured 3rd position – SignLangApp.\\n\\n\\tSIH Zonal Round 2023: Secured 4th position in Top 15 – DeepDefend.\\n\\n\\tTexephyr 2022: Secured 3rd position & management role - created a CNN from scratch (w/o tensorflow) for Vehicle Detection.\\n\\nEXTRA CURRICULAR ACTIVITIES\\n\\n\\n\\n\\tEEE Department Basketball Team Captain – 7 major victories.\\n\\n\\tTrinity College of Music London - Piano Grade 5 Distinction.')"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
        "documents_embeddings = embeddings.embed_documents([split.page_content for split in splits])\n",
        "print(f\"Created embeddings for {len(documents_embeddings)} doc chunks\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ltrf-WYomUVJ",
        "outputId": "cdef6905-f5ce-4cc1-a2df-5b6f7070a060"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created embeddings for 12 doc chunks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_chroma import Chroma\n",
        "embedding_function = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
        "collection_name = \"myCollection\"\n",
        "vectorstore = Chroma.from_documents(\n",
        "    collection_name=collection_name,\n",
        "    documents=splits,\n",
        "    embedding=embedding_function,\n",
        "    persist_directory=\"./chroma_DB\"\n",
        ")\n",
        "print(\"Vector store created and persisted to ChromaDB\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VRTZ0s8-my8T",
        "outputId": "a95f80a1-2086-4f7c-82fa-145e36777a5f"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vector store created and persisted to ChromaDB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What is the resume summary?\"\n",
        "search_results = vectorstore.similarity_search(query, k=2)\n",
        "print(f\"\\nTop 2 most relevant search for the query: {query} \\n\")\n",
        "\n",
        "for i, res in enumerate(search_results, 1):\n",
        "  print(f\"Result  : {i}\")\n",
        "  print(f\"Source  : {res.metadata.get('source', 'Unknown')}\")\n",
        "  print(f\"Content : {res.page_content}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u3Pi7pXpnzMn",
        "outputId": "907f5261-b1d9-4b93-b205-f8382287cae6"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Top 2 most relevant search for the query: What is the resume summary? \n",
            "\n",
            "Result  : 1\n",
            "Source  : /content/docs/Aryan_Chauhan_Resume.docx\n",
            "Content : Symbiosis Primary & Secondary School, Pune, India\t   Aug 2020\n",
            "\n",
            "Secured 83.20% in Class 10th examination (SSC Board)\n",
            "\n",
            "\n",
            "\n",
            "EXPERIENCE\n",
            "\n",
            "\tInnovators Hub, Pune \t    Pune, India\n",
            "\n",
            "\tCore Software Team Member (7+ months)\t     Aug 2024 – Present 2025\n",
            "\n",
            "\t\tContributor to design & development of Neural Network powered applications. Lead a team of 5 which successfully developed a Computer Vision AI-powered interview system enabling real-time, bidirectional communication for individuals with speech and hearing impairments for Centre for Education and R&D for Deaf and Dumb, Pune.\n",
            "\n",
            "\tRancho Labs, IIT-Delhi (2 months)\t    Remote Setup\n",
            "\n",
            "\tAdvanced AI & Python Instructor\t     May 2025 – Sept 2025\n",
            "\n",
            "\tMentoring young aspiring developers by teaching them DSA, NLP, GenAI, Python and Advance AI algorithms from the ground up, enabling them to build & deploy real-world applications.\n",
            "\n",
            "\tTexephyr, MIT Pune (17 months)\t        Pune, India\n",
            "\n",
            "\tTechnical Manager\t         Mar 2022 – Jul 2023\n",
            "Result  : 2\n",
            "Source  : /content/docs/Aryan_Chauhan_Resume.docx\n",
            "Content : Symbiosis Primary & Secondary School, Pune, India\t   Aug 2020\n",
            "\n",
            "Secured 83.20% in Class 10th examination (SSC Board)\n",
            "\n",
            "\n",
            "\n",
            "EXPERIENCE\n",
            "\n",
            "\tInnovators Hub, Pune \t    Pune, India\n",
            "\n",
            "\tCore Software Team Member (7+ months)\t     Aug 2024 – Present 2025\n",
            "\n",
            "\t\tContributor to design & development of Neural Network powered applications. Lead a team of 5 which successfully developed a Computer Vision AI-powered interview system enabling real-time, bidirectional communication for individuals with speech and hearing impairments for Centre for Education and R&D for Deaf and Dumb, Pune.\n",
            "\n",
            "\tRancho Labs, IIT-Delhi (2 months)\t    Remote Setup\n",
            "\n",
            "\tAdvanced AI & Python Instructor\t     May 2025 – Sept 2025\n",
            "\n",
            "\tMentoring young aspiring developers by teaching them DSA, NLP, GenAI, Python and Advance AI algorithms from the ground up, enabling them to build & deploy real-world applications.\n",
            "\n",
            "\tTexephyr, MIT Pune (17 months)\t        Pune, India\n",
            "\n",
            "\tTechnical Manager\t         Mar 2022 – Jul 2023\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 2})\n",
        "retriever_results = retriever.invoke(\"Who is the candidate whose cv we are seeing?\")\n",
        "print(retriever_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x6ZsRWompoQg",
        "outputId": "8dd7b701-5e13-4209-8211-7917f5048749"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Document(id='e4b8e71f-db69-40d6-8704-33b079ab86e6', metadata={'source': '/content/docs/Aryan_Chauhan_Resume.docx'}, page_content='DeepDefend (4 months) – Computer Vision\\t        Sept 2023 – Dec 2023\\n\\n\\tAn AI-powered system for detecting face-swap deepfake videos using advanced facial forensics and Computer Vision models like CNNs, Resnet50, VGG16 and real-time image processing techniques to ensure content authenticity and combat misinformation.\\n\\nSKILLS & LANGUAGE PROFICIENCY\\n\\n\\t\\tLanguages: C, C++, Java, Python, HTML, CSS, JavaScript.\\n\\n\\t\\tNeural Networks: ANN, CNN, RNN, LSTM & BiLSTM, GRU & BiGRU, Transformers, Attention Mechanism.\\n\\n\\t\\tNLP: Whisper, Wav2Vec, Conformer, Tacotron, FastSpeech, VITS, VoiceCloning, Neural Vocoders, MFCCs, STT.\\n\\n\\tComputer Vision: Yolo, Vision Transformers, Real-time Video & Image Processing, GAN, Opencv, Mediapipe, Dlib.\\n\\n\\tAI and AgenticAI Infrastructure: PyTorch, Tensorflow, Keras, HuggingFace, Langchain, LoRa, QLoRa, RAG, MCP.\\n\\n\\tWebDev Infrastructure: MERN, React, UI/UX, AWS, RunPod, FastAPI, Flask, Firebase, Streamlit.'), Document(id='d62dc2d4-7963-4166-bd0f-d7fb83fdb7d4', metadata={'source': '/content/docs/Aryan_Chauhan_Resume.docx'}, page_content='DeepDefend (4 months) – Computer Vision\\t        Sept 2023 – Dec 2023\\n\\n\\tAn AI-powered system for detecting face-swap deepfake videos using advanced facial forensics and Computer Vision models like CNNs, Resnet50, VGG16 and real-time image processing techniques to ensure content authenticity and combat misinformation.\\n\\nSKILLS & LANGUAGE PROFICIENCY\\n\\n\\t\\tLanguages: C, C++, Java, Python, HTML, CSS, JavaScript.\\n\\n\\t\\tNeural Networks: ANN, CNN, RNN, LSTM & BiLSTM, GRU & BiGRU, Transformers, Attention Mechanism.\\n\\n\\t\\tNLP: Whisper, Wav2Vec, Conformer, Tacotron, FastSpeech, VITS, VoiceCloning, Neural Vocoders, MFCCs, STT.\\n\\n\\tComputer Vision: Yolo, Vision Transformers, Real-time Video & Image Processing, GAN, Opencv, Mediapipe, Dlib.\\n\\n\\tAI and AgenticAI Infrastructure: PyTorch, Tensorflow, Keras, HuggingFace, Langchain, LoRa, QLoRa, RAG, MCP.\\n\\n\\tWebDev Infrastructure: MERN, React, UI/UX, AWS, RunPod, FastAPI, Flask, Firebase, Streamlit.')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# building the RAG chain\n",
        "\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain.schema.runnable import RunnablePassthrough\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "template = '''\n",
        "Answer the question based only on the following context: {context}\n",
        "Question: {question}\n",
        "'''\n",
        "\n",
        "prompt = ChatPromptTemplate.from_template(template)\n",
        "\n",
        "def docs2str(docs):\n",
        "  return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
        "\n",
        "rag_chain = (\n",
        "    {\"context\":retriever | docs2str, \"question\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")"
      ],
      "metadata": {
        "id": "H00HBCfoqiov"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question=\"Tell me the entire education of the person\"\n",
        "res = rag_chain.invoke(question)\n",
        "print(res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cySA6KtSryGx",
        "outputId": "21115e8f-5897-450f-98e3-1357f783b4b7"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The person's education consists of attending Symbiosis Primary & Secondary School, Pune, India, where they secured 83.20% in the Class 10th examination (SSC Board) in August 2020.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# history aware retriever -> model understand of the conversation\n",
        "\n",
        "from langchain_core.prompts import MessagesPlaceholder\n",
        "from langchain.chains import create_history_aware_retriever\n",
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "\n",
        "context_q_system_prompt = '''\n",
        "Given a chat history and latest user question which might reference context in chat history,\n",
        "formulate a standalone question which can be understood without the\n",
        "chat history and do not answer the question,\n",
        "just formulate if needed and otherwise return as it it.\n",
        "'''\n",
        "\n",
        "context_q_prompt=ChatPromptTemplate.from_messages([\n",
        "    (\"system\", context_q_system_prompt),\n",
        "    MessagesPlaceholder(\"chat_history\"),\n",
        "    (\"human\", \"{input}\")\n",
        "])\n",
        "\n",
        "context_chain = context_q_prompt | llm | StrOutputParser()\n",
        "print(context_chain.invoke({\"input\": \"What is his CGPA?\", \"chat_history\": []}))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MguWj4-nr9Dj",
        "outputId": "9c1e40ed-5fdd-4c5b-ccd0-22f91e05bbfc"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What is [Name]'s CGPA?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import create_retrieval_chain\n",
        "\n",
        "history_aware_ret = create_history_aware_retriever(\n",
        "    llm, retriever, context_q_prompt\n",
        ")\n",
        "\n",
        "qa_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are a helpful assistant. Use the following context to answer user question\"),\n",
        "    (\"system\", \"Context: {context}\"),\n",
        "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
        "    (\"human\", \"{input}\")\n",
        "])\n",
        "\n",
        "queston_answer = create_stuff_documents_chain(llm, qa_prompt)\n",
        "rag_chain=create_retrieval_chain(history_aware_ret, queston_answer)"
      ],
      "metadata": {
        "id": "iWCaxTWBuW44"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import HumanMessage, AIMessage\n",
        "\n",
        "chat_history = []\n",
        "question1 = \"Tell me about his projects\"\n",
        "answer1 = rag_chain.invoke({\"input\": question1, \"chat_history\": chat_history})['answer']\n",
        "\n",
        "chat_history.extend([\n",
        "    HumanMessage(content=question1),\n",
        "    AIMessage(content=answer1)\n",
        "])\n",
        "\n",
        "print(question1)\n",
        "print(answer1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "at_elr32vhZO",
        "outputId": "21ef18ec-9f17-4a8a-a036-41b550b723a5"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tell me about his projects\n",
            "Based on the provided text, here are the projects mentioned:\n",
            "\n",
            "1.  **Koel**\n",
            "    *   **Type:** NLP (Multilingual Voice-to-Voice AI System)\n",
            "    *   **Duration:** 2 months (May 2025 – Jun 2025)\n",
            "    *   **Description:** Developed an intelligent, multilingual voice-to-voice AI system that enables real-time natural conversations in Indian languages. It was built with React Native and FastAPI, integrates Sarvam-M LLM with RAG for PDF-based contextual responses, delivers real-time web results, and ensures low-latency voice processing through a scalable architecture.\n",
            "\n",
            "2.  **DeepDefend**\n",
            "    *   **Type:** Computer Vision (Deepfake Detection System)\n",
            "    *   **Duration:** 4 months (Sept 2023 – Dec 2023)\n",
            "    *   **Description:** An AI-powered system for detecting face-swap deepfake videos. It uses advanced facial forensics and Computer Vision models like CNNs, Resnet50, VGG15, and real-time image processing techniques to ensure content authenticity and combat misinformation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3EzwFXSGwGm3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}